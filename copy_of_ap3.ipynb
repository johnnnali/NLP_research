{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "zgqd68NkBs5m",
        "outputId": "3424db43-b655-4a89-935f-275dc06ac963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/159 Proj Copy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2f5235381cfd>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/159 Proj Copy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/159 Proj Copy'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/159 Proj Copy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xk9QLZT4lM6",
        "outputId": "3174ca0d-2c24-40d9-bd2e-764a490472a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting clean-text\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text)\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.13)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171034 sha256=12eeb738269211501a6a3b6163b18f86d6c338aae80b8117fb721c932cd8ca6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, ftfy, clean-text\n",
            "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.2.0\n",
            "Requirement already satisfied: clean-text in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from clean-text) (1.7.0)\n",
            "Requirement already satisfied: ftfy<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from clean-text) (6.2.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.13)\n",
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.13.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n"
          ]
        }
      ],
      "source": [
        "!pip install clean-text emoji\n",
        "!pip install clean-text\n",
        "!pip install nlpaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQhCl110Idhh",
        "outputId": "99362e58-04bc-4e04-e478-83de55d5b7ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx854igYFeB5"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTlgB2vZFdjK",
        "outputId": "f03fbc33-41a8-45e3-b905-c72f9ab05b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package opinion_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "from scipy import sparse\n",
        "from sklearn import linear_model\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import operator\n",
        "import nltk\n",
        "import math\n",
        "from scipy.stats import norm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "from cleantext import clean\n",
        "import re\n",
        "import emoji\n",
        "from ast import literal_eval\n",
        "\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.preprocessing import normalize\n",
        "from nltk.corpus import opinion_lexicon\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('opinion_lexicon')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw8XtDi-H-nL"
      },
      "source": [
        "# Load and create Splits folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYhF-AXYGHRd",
        "outputId": "6752c5fb-17ea-43a4-d9a5-97113cd6d4b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     index_id  adjudicated  Troll Rating  \\\n",
              "0           0  adjudicated             2   \n",
              "1           1  adjudicated             5   \n",
              "2           2  adjudicated             5   \n",
              "3           3  adjudicated             5   \n",
              "4           4  adjudicated             1   \n",
              "..        ...          ...           ...   \n",
              "495       495  adjudicated             4   \n",
              "496       496  adjudicated             1   \n",
              "497       497  adjudicated             1   \n",
              "498       498  adjudicated             2   \n",
              "499       499  adjudicated             1   \n",
              "\n",
              "                                                  Post  \n",
              "0    Title: Some of yall are so backhanded   The am...  \n",
              "1    Title: Dear Fellow UC Berkeley Students  I‚Äôve ...  \n",
              "2                 Title: I want to lose my virginity.   \n",
              "3    Title: UniversityFuck people‚Äôs park üòπ  Activis...  \n",
              "4    Title: UniversityEnough is enough. It‚Äôs time t...  \n",
              "..                                                 ...  \n",
              "495  Sex Ed at Berkeley. So I am an incoming freshm...  \n",
              "496  Has anyone been charged with a \"Minor in Posse...  \n",
              "497  Why are general questions downvoted so heavily...  \n",
              "498  Fuck the high demand major policy. The whole p...  \n",
              "499  1 Bedroom in Downtown Berkeley for $1,350 Avai...  \n",
              "\n",
              "[500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b252631-9b2e-4db4-8b77-b24152d77aac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index_id</th>\n",
              "      <th>adjudicated</th>\n",
              "      <th>Troll Rating</th>\n",
              "      <th>Post</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>2</td>\n",
              "      <td>Title: Some of yall are so backhanded   The am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>5</td>\n",
              "      <td>Title: Dear Fellow UC Berkeley Students  I‚Äôve ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>5</td>\n",
              "      <td>Title: I want to lose my virginity.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>5</td>\n",
              "      <td>Title: UniversityFuck people‚Äôs park üòπ  Activis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>1</td>\n",
              "      <td>Title: UniversityEnough is enough. It‚Äôs time t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>495</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>4</td>\n",
              "      <td>Sex Ed at Berkeley. So I am an incoming freshm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>496</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>1</td>\n",
              "      <td>Has anyone been charged with a \"Minor in Posse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>497</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>1</td>\n",
              "      <td>Why are general questions downvoted so heavily...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>498</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>2</td>\n",
              "      <td>Fuck the high demand major policy. The whole p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>499</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>1</td>\n",
              "      <td>1 Bedroom in Downtown Berkeley for $1,350 Avai...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows √ó 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b252631-9b2e-4db4-8b77-b24152d77aac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8b252631-9b2e-4db4-8b77-b24152d77aac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8b252631-9b2e-4db4-8b77-b24152d77aac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9e73a4dc-01a6-447d-a1ec-bde0e3f25146\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e73a4dc-01a6-447d-a1ec-bde0e3f25146')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9e73a4dc-01a6-447d-a1ec-bde0e3f25146 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "adj_data",
              "summary": "{\n  \"name\": \"adj_data\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"index_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 144,\n        \"min\": 0,\n        \"max\": 499,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          361,\n          73,\n          374\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adjudicated\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"adjudicated\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Troll Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Post\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"Is the Berkeley experience better? I have two options; I can either take online college now and become an military officer (40-50k+ per year) OR I can wait and go through military as enlisted (25-35k per year), foregoing an online bachelor's for the sake of going to Berkeley later and getting the traditional experience at a top school.  I've never been to college before, and I'm wondering whether the Uni experience is something I should hold out for.  I can still go to brick and mortar Uni if I get the online degree and get that traditional experience; but it won't be Berkeley or any other UC, unless I manage to get into a graduate program (which I assume will be harder to do with an online degree).  My majors are between Computer Science and Physics -- the computer science I can do anywhere, but Physics I feel would benefit from research labs.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "adj_data = pd.read_csv('adj-1.txt', sep='\\t', header=None, names=['index_id', 'adjudicated', 'Troll Rating','Post'], index_col=False)\n",
        "adj_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STkGIZg5aEB8"
      },
      "outputs": [],
      "source": [
        "# Split the data into training (60%), development (20%), and test (20%)\n",
        "train, temp = train_test_split(adj_data, test_size=0.4, random_state=42)  # First split for 60% training\n",
        "dev, test = train_test_split(temp, test_size=0.5, random_state=42)   # Second split for 20% dev and 20% test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QscfLOLEBt-w",
        "outputId": "eb0ea3c3-cea1-4651-aa0f-91d8c85798cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/159 Proj Copy/splits/train.txt',\n",
              " '/content/drive/MyDrive/159 Proj Copy/splits/dev.txt',\n",
              " '/content/drive/MyDrive/159 Proj Copy/splits/test.txt')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Directory to store the splits\n",
        "split_dir = '/content/drive/MyDrive/159 Proj Copy/splits'\n",
        "os.makedirs(split_dir, exist_ok=True)\n",
        "\n",
        "# Save the splits to files\n",
        "train.to_csv(os.path.join(split_dir, 'train.txt'), sep='\\t', index=False, header=False)\n",
        "dev.to_csv(os.path.join(split_dir, 'dev.txt'), sep='\\t', index=False, header=False)\n",
        "test.to_csv(os.path.join(split_dir, 'test.txt'), sep='\\t', index=False, header=False)\n",
        "\n",
        "# Outputs the paths to the created files\n",
        "train_path = os.path.join(split_dir, 'train.txt')\n",
        "dev_path = os.path.join(split_dir, 'dev.txt')\n",
        "test_path = os.path.join(split_dir, 'test.txt')\n",
        "\n",
        "train_path, dev_path, test_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBZrPpk2Ua3z",
        "outputId": "5516a8ae-c77d-4279-a5d2-129084c4d6e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why is race absent in WarnMe descriptions? title. doesn't make any logical sense - if you want to protect students its not helpful to know the color of their hoodie.  \n",
            " 3\n"
          ]
        }
      ],
      "source": [
        "def load_data(filename):\n",
        "    X = []\n",
        "    Y = []\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            cols = line.split(\"\\t\")\n",
        "            idd = cols[0]\n",
        "            label = cols[2].lstrip().rstrip()\n",
        "            text = cols[3]\n",
        "\n",
        "            X.append(text)\n",
        "            Y.append(label)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "trainingFile = \"splits/train.txt\"\n",
        "devFile = \"splits/dev.txt\"\n",
        "testFile = \"splits/test.txt\"\n",
        "\n",
        "trainX, trainY=load_data(trainingFile)\n",
        "devX, devY=load_data(devFile)\n",
        "testX, testY=load_data(testFile)\n",
        "\n",
        "print(trainX[0], trainY[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFaXoyc7msH8"
      },
      "source": [
        "# Baseline Models without any changes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQWXEf9RoPhc"
      },
      "source": [
        "## Majority class classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4GTksOZnXzP",
        "outputId": "3b2132d6-10d8-4ae4-87a0-fe562611532b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Majority class: 1, dev accuracy: 0.450, test accuracy: 0.410\n"
          ]
        }
      ],
      "source": [
        "def majority_class(trainY, evalY):\n",
        "    labelCounts=Counter()\n",
        "    for label in trainY:\n",
        "        labelCounts[label]+=1\n",
        "    majority_class=labelCounts.most_common(1)[0][0]\n",
        "\n",
        "    correct=0.\n",
        "    for label in evalY:\n",
        "        if label == majority_class:\n",
        "            correct+=1\n",
        "    return majority_class, correct/len(evalY)\n",
        "\n",
        "\n",
        "mc, mc_devAcc=majority_class(trainY, devY)\n",
        "_, mc_testAcc=majority_class(trainY, testY)\n",
        "\n",
        "print(\"Majority class: %s, dev accuracy: %.3f, test accuracy: %.3f\" % (mc, mc_devAcc, mc_testAcc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnLJu4lHoR9W"
      },
      "source": [
        "## Logistics Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8S_1r6Xnhwv"
      },
      "outputs": [],
      "source": [
        "class Classifier:\n",
        "\n",
        "    def __init__(self, feature_method, trainX, trainY, devX, devY, testX, testY):\n",
        "        self.feature_vocab = {}\n",
        "        self.feature_method = feature_method\n",
        "        self.min_feature_count=2\n",
        "        self.log_reg = None\n",
        "\n",
        "        self.trainY=trainY\n",
        "        self.devY=devY\n",
        "        self.testY=testY\n",
        "\n",
        "        self.trainX = self.process(trainX, training=True)\n",
        "        self.devX = self.process(devX, training=False)\n",
        "        self.testX = self.process(testX, training=False)\n",
        "\n",
        "    # Featurize entire dataset\n",
        "    def featurize(self, data):\n",
        "        featurized_data = []\n",
        "        for text in data:\n",
        "            feats = self.feature_method(text)\n",
        "            featurized_data.append(feats)\n",
        "        return featurized_data\n",
        "\n",
        "    # Read dataset and returned featurized representation as sparse matrix + label array\n",
        "    def process(self, X_data, training = False):\n",
        "\n",
        "        data = self.featurize(X_data)\n",
        "\n",
        "        if training:\n",
        "            fid = 0\n",
        "            feature_doc_count = Counter()\n",
        "            for feats in data:\n",
        "                for feat in feats:\n",
        "                    feature_doc_count[feat]+= 1\n",
        "\n",
        "            for feat in feature_doc_count:\n",
        "                if feature_doc_count[feat] >= self.min_feature_count:\n",
        "                    self.feature_vocab[feat] = fid\n",
        "                    fid += 1\n",
        "\n",
        "        F = len(self.feature_vocab)\n",
        "        D = len(data)\n",
        "        X = sparse.dok_matrix((D, F))\n",
        "        for idx, feats in enumerate(data):\n",
        "            for feat in feats:\n",
        "                if feat in self.feature_vocab:\n",
        "                    X[idx, self.feature_vocab[feat]] = feats[feat]\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "    # Train model and evaluate on held-out data\n",
        "    def train(self):\n",
        "        (D,F) = self.trainX.shape\n",
        "        best_dev_accuracy=0\n",
        "        best_model=None\n",
        "        for C in [0.1, 1, 10, 100]:\n",
        "            self.log_reg = linear_model.LogisticRegression(C = C, max_iter=1000)\n",
        "            self.log_reg.fit(self.trainX, self.trainY)\n",
        "            training_accuracy = self.log_reg.score(self.trainX, self.trainY)\n",
        "            development_accuracy = self.log_reg.score(self.devX, self.devY)\n",
        "            if development_accuracy > best_dev_accuracy:\n",
        "                best_dev_accuracy=development_accuracy\n",
        "                best_model=self.log_reg\n",
        "\n",
        "#             print(\"C: %s, Train accuracy: %.3f, Dev accuracy: %.3f\" % (C, training_accuracy, development_accuracy))\n",
        "\n",
        "        self.log_reg=best_model\n",
        "\n",
        "\n",
        "    def test(self):\n",
        "        return self.log_reg.score(self.testX, self.testY)\n",
        "\n",
        "\n",
        "    def printWeights(self, n=10):\n",
        "\n",
        "        reverse_vocab=[None]*len(self.log_reg.coef_[0])\n",
        "        for k in self.feature_vocab:\n",
        "            reverse_vocab[self.feature_vocab[k]]=k\n",
        "\n",
        "        # binary\n",
        "        if len(self.log_reg.classes_) == 2:\n",
        "              weights=self.log_reg.coef_[0]\n",
        "\n",
        "              cat=self.log_reg.classes_[1]\n",
        "              for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
        "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
        "              print()\n",
        "\n",
        "              cat=self.log_reg.classes_[0]\n",
        "              for feature, weight in list(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1)))[:n]:\n",
        "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
        "              print()\n",
        "\n",
        "        # multiclass\n",
        "        else:\n",
        "          for i, cat in enumerate(self.log_reg.classes_):\n",
        "\n",
        "              weights=self.log_reg.coef_[i]\n",
        "\n",
        "              for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
        "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
        "              print()\n",
        "\n",
        "\n",
        "def binary_bow_featurize(text):\n",
        "    feats = {}\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    for word in words:\n",
        "        word=word.lower()\n",
        "        feats[word]=1\n",
        "\n",
        "    # print(feats)\n",
        "    return feats\n",
        "\n",
        "def confidence_intervals(accuracy, n, significance_level):\n",
        "    critical_value=(1-significance_level)/2\n",
        "    z_alpha=-1*norm.ppf(critical_value)\n",
        "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
        "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9vSbBFwTgUP"
      },
      "outputs": [],
      "source": [
        "def run(trainingFile, devFile, testFile):\n",
        "    trainX, trainY=load_data(trainingFile)\n",
        "    devX, devY=load_data(devFile)\n",
        "    testX, testY=load_data(testFile)\n",
        "\n",
        "    simple_classifier = Classifier(binary_bow_featurize, trainX, trainY, devX, devY, testX, testY)\n",
        "    simple_classifier.train()\n",
        "    accuracy=simple_classifier.test()\n",
        "\n",
        "    lower, upper=confidence_intervals(accuracy, len(testY), .95)\n",
        "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))\n",
        "\n",
        "    simple_classifier.printWeights()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXLI44LvTh6l",
        "outputId": "f3dd2263-e425-4ba8-d458-c70c06e27b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.420, 95% CIs: [0.323 0.517]\n",
            "\n",
            "1\t0.260\tso\n",
            "1\t0.251\tyear\n",
            "1\t0.249\tfor\n",
            "1\t0.221\ts\n",
            "1\t0.216\tor\n",
            "1\t0.207\t!\n",
            "1\t0.196\tlast\n",
            "1\t0.195\thaving\n",
            "1\t0.176\tat\n",
            "1\t0.175\ta\n",
            "\n",
            "2\t0.213\tby\n",
            "2\t0.199\t,\n",
            "2\t0.188\tcome\n",
            "2\t0.186\tthe\n",
            "2\t0.175\t*\n",
            "2\t0.164\tworld\n",
            "2\t0.162\tsubmitted\n",
            "2\t0.155\tself.berkeley\n",
            "2\t0.142\tbecause\n",
            "2\t0.136\tbut\n",
            "\n",
            "3\t0.322\tpeople\n",
            "3\t0.196\tme\n",
            "3\t0.194\twhy\n",
            "3\t0.179\tand\n",
            "3\t0.178\tget\n",
            "3\t0.175\tgood\n",
            "3\t0.167\ttitle\n",
            "3\t0.164\tother\n",
            "3\t0.162\ttake\n",
            "3\t0.154\tthe\n",
            "\n",
            "4\t0.228\tover\n",
            "4\t0.177\tmost\n",
            "4\t0.160\tin\n",
            "4\t0.157\tn't\n",
            "4\t0.134\tsuch\n",
            "4\t0.130\t's\n",
            "4\t0.128\tmonths\n",
            "4\t0.125\tdue\n",
            "4\t0.122\teveryone\n",
            "4\t0.120\tthose\n",
            "\n",
            "5\t0.225\ton\n",
            "5\t0.188\tgot\n",
            "5\t0.177\tmy\n",
            "5\t0.172\treal\n",
            "5\t0.159\thow\n",
            "5\t0.151\tcan\n",
            "5\t0.138\tlove\n",
            "5\t0.132\tfriend\n",
            "5\t0.126\tbest\n",
            "5\t0.123\t!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainingFile = \"splits/train.txt\"\n",
        "devFile = \"splits/dev.txt\"\n",
        "testFile = \"splits/test.txt\"\n",
        "\n",
        "run(trainingFile, devFile, testFile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_U0IID2U-4H"
      },
      "source": [
        "## Ordinal Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RV-_AY7VVHMc"
      },
      "outputs": [],
      "source": [
        "def load_ordinal_data(filename, ordering):\n",
        "    X = []\n",
        "    Y = []\n",
        "    orig_Y=[]\n",
        "    for ordinal in ordering:\n",
        "        Y.append([])\n",
        "\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            cols = line.split(\"\\t\")\n",
        "            idd = cols[0]\n",
        "            label = cols[2].lstrip().rstrip()\n",
        "            text = cols[3]\n",
        "\n",
        "            X.append(text)\n",
        "\n",
        "            index=ordering.index(label)\n",
        "            for i in range(len(ordering)):\n",
        "                if index > i:\n",
        "                    Y[i].append(1)\n",
        "                else:\n",
        "                    Y[i].append(0)\n",
        "            orig_Y.append(label)\n",
        "\n",
        "    return X, Y, orig_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFRRGXj-VHJz"
      },
      "outputs": [],
      "source": [
        "class OrdinalClassifier:\n",
        "\n",
        "    def __init__(self, ordinal_values, feature_method, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY):\n",
        "        self.ordinal_values=ordinal_values\n",
        "        self.feature_vocab = {}\n",
        "        self.feature_method = feature_method\n",
        "        self.min_feature_count=2\n",
        "        self.log_regs = [None]* (len(self.ordinal_values)-1)\n",
        "\n",
        "        self.trainY=trainY\n",
        "        self.devY=devY\n",
        "        self.testY=testY\n",
        "\n",
        "        self.orig_trainY=orig_trainY\n",
        "        self.orig_devY=orig_devY\n",
        "        self.orig_testY=orig_testY\n",
        "\n",
        "        self.trainX = self.process(trainX, training=True)\n",
        "        self.devX = self.process(devX, training=False)\n",
        "        self.testX = self.process(testX, training=False)\n",
        "\n",
        "    # Featurize entire dataset\n",
        "    def featurize(self, data):\n",
        "        featurized_data = []\n",
        "        for text in data:\n",
        "            feats = self.feature_method(text)\n",
        "            featurized_data.append(feats)\n",
        "        return featurized_data\n",
        "\n",
        "    # Read dataset and returned featurized representation as sparse matrix + label array\n",
        "    def process(self, X_data, training = False):\n",
        "\n",
        "        data = self.featurize(X_data)\n",
        "\n",
        "        if training:\n",
        "            fid = 0\n",
        "            feature_doc_count = Counter()\n",
        "            for feats in data:\n",
        "                for feat in feats:\n",
        "                    feature_doc_count[feat]+= 1\n",
        "\n",
        "            for feat in feature_doc_count:\n",
        "                if feature_doc_count[feat] >= self.min_feature_count:\n",
        "                    self.feature_vocab[feat] = fid\n",
        "                    fid += 1\n",
        "\n",
        "        F = len(self.feature_vocab)\n",
        "        D = len(data)\n",
        "        X = sparse.dok_matrix((D, F))\n",
        "        for idx, feats in enumerate(data):\n",
        "            for feat in feats:\n",
        "                if feat in self.feature_vocab:\n",
        "                    X[idx, self.feature_vocab[feat]] = feats[feat]\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        (D,F) = self.trainX.shape\n",
        "\n",
        "\n",
        "        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n",
        "            best_dev_accuracy=0\n",
        "            best_model=None\n",
        "            for C in [0.1, 1, 10, 100]:\n",
        "\n",
        "                log_reg = linear_model.LogisticRegression(C = C, max_iter=1000)\n",
        "                log_reg.fit(self.trainX, self.trainY[idx])\n",
        "                development_accuracy = log_reg.score(self.devX, self.devY[idx])\n",
        "                if development_accuracy > best_dev_accuracy:\n",
        "                    best_dev_accuracy=development_accuracy\n",
        "                    best_model=log_reg\n",
        "\n",
        "\n",
        "            self.log_regs[idx]=best_model\n",
        "\n",
        "    def test(self):\n",
        "        cor=tot=0\n",
        "        counts=Counter()\n",
        "        preds=[None]*(len(self.ordinal_values)-1)\n",
        "        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n",
        "            preds[idx]=self.log_regs[idx].predict_proba(self.testX)[:,1]\n",
        "\n",
        "        preds=np.array(preds)\n",
        "\n",
        "        for data_point in range(len(preds[0])):\n",
        "\n",
        "\n",
        "            ordinal_preds=np.zeros(len(self.ordinal_values))\n",
        "            for ordinal in range(len(self.ordinal_values)-1):\n",
        "                if ordinal == 0:\n",
        "                    ordinal_preds[ordinal]=1-preds[ordinal][data_point]\n",
        "                else:\n",
        "                    ordinal_preds[ordinal]=preds[ordinal-1][data_point]-preds[ordinal][data_point]\n",
        "\n",
        "            ordinal_preds[len(self.ordinal_values)-1]=preds[len(preds)-1][data_point]\n",
        "\n",
        "            prediction=np.argmax(ordinal_preds)\n",
        "            counts[prediction]+=1\n",
        "            if prediction == self.ordinal_values.index(self.orig_testY[data_point]):\n",
        "                cor+=1\n",
        "            tot+=1\n",
        "\n",
        "        return cor/tot\n",
        "\n",
        "\n",
        "def binary_bow_featurize(text):\n",
        "    feats = {}\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    for word in words:\n",
        "        word=word.lower()\n",
        "        feats[word]=1\n",
        "\n",
        "    return feats\n",
        "\n",
        "def confidence_intervals(accuracy, n, significance_level):\n",
        "    critical_value=(1-significance_level)/2\n",
        "    z_alpha=-1*norm.ppf(critical_value)\n",
        "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
        "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w4XmsidVHHc"
      },
      "outputs": [],
      "source": [
        "def run(trainingFile, devFile, testFile, ordinal_values):\n",
        "\n",
        "\n",
        "    trainX, trainY, orig_trainY=load_ordinal_data(trainingFile, ordinal_values)\n",
        "    devX, devY, orig_devY=load_ordinal_data(devFile, ordinal_values)\n",
        "    testX, testY, orig_testY=load_ordinal_data(testFile, ordinal_values)\n",
        "\n",
        "    simple_classifier = OrdinalClassifier(ordinal_values, binary_bow_featurize, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY)\n",
        "    simple_classifier.train()\n",
        "    accuracy=simple_classifier.test()\n",
        "\n",
        "    lower, upper=confidence_intervals(accuracy, len(testY[0]), .95)\n",
        "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuZInVAFVHE6",
        "outputId": "4b2433eb-ca98-4dd0-da15-1e264e7f3498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.400, 95% CIs: [0.304 0.496]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainingFile = \"splits/train.txt\"\n",
        "devFile = \"splits/dev.txt\"\n",
        "testFile = \"splits/test.txt\"\n",
        "\n",
        "ordinal_values=[\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
        "\n",
        "run(trainingFile, devFile, testFile, ordinal_values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def test_and_evaluate(classifier, testX, testY):\n",
        "    predictions = classifier.log_reg.predict(testX)\n",
        "\n",
        "    test_accuracy = classifier.log_reg.score(testX, testY)\n",
        "\n",
        "    conf_matrix = confusion_matrix(testY, predictions)\n",
        "\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classifier.log_reg.classes_, yticklabels=classifier.log_reg.classes_)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    return test_accuracy, conf_matrix\n",
        "\n",
        "simple_classifier = Classifier(binary_bow_featurize, trainX, trainY, devX, devY, testX, testY)\n",
        "simple_classifier.train()\n",
        "test_accuracy, conf_matrix = test_and_evaluate(simple_classifier, simple_classifier.testX, simple_classifier.testY)\n",
        "\n",
        "print(\"Test Accuracy: {:.3f}\".format(test_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "DATlqggjmA9c",
        "outputId": "9b32a238-bd50-42af-9a73-3b6758183286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Classifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-098e43c9d281>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Example of using this function in your run function:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0msimple_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_bow_featurize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0msimple_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Classifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6n46bL2XCDs"
      },
      "source": [
        "## BERT Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG1LRcApXy25",
        "outputId": "8614e278-1f56-4443-a509-e894f8b94db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on {}\".format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASXgdrb8Xy0f"
      },
      "outputs": [],
      "source": [
        "def read_labels(filename):\n",
        "    labels={}\n",
        "    with open(filename) as file:\n",
        "        for line in file:\n",
        "            cols = line.split(\"\\t\")\n",
        "            label = cols[2]\n",
        "            if label not in labels:\n",
        "                labels[label]=len(labels)\n",
        "    return labels\n",
        "\n",
        "def read_data(filename, labels, max_data_points=1000):\n",
        "\n",
        "    data = []\n",
        "    data_labels = []\n",
        "    with open(filename) as file:\n",
        "        for line in file:\n",
        "            cols = line.split(\"\\t\")\n",
        "            label = cols[2]\n",
        "            text = cols[3]\n",
        "\n",
        "            data.append(text)\n",
        "            data_labels.append(labels[label])\n",
        "\n",
        "\n",
        "    # shuffle the data\n",
        "    tmp = list(zip(data, data_labels))\n",
        "    random.shuffle(tmp)\n",
        "    data, data_labels = zip(*tmp)\n",
        "\n",
        "    if max_data_points is None:\n",
        "        return data, data_labels\n",
        "\n",
        "    return data[:max_data_points], data_labels[:max_data_points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIrVha2SYwAx"
      },
      "outputs": [],
      "source": [
        "directory='/content/drive/MyDrive/159 Proj Copy/splits'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BQ2aGhhXyw5"
      },
      "outputs": [],
      "source": [
        "labels=read_labels(\"%s/train.txt\" % directory)\n",
        "train_x, train_y=read_data(\"%s/train.txt\" % directory, labels, max_data_points=None)\n",
        "dev_x, dev_y=read_data(\"%s/dev.txt\" % directory, labels, max_data_points=None)\n",
        "test_x, test_y=read_data(\"%s/test.txt\" % directory, labels, max_data_points=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgplpNihZQLf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate(model, x, y):\n",
        "    model.eval()\n",
        "    corr = 0.\n",
        "    total = 0.\n",
        "    with torch.no_grad():\n",
        "        for x, y in zip(x, y):\n",
        "            y_preds=model.forward(x)\n",
        "            for idx, y_pred in enumerate(y_preds):\n",
        "                prediction=torch.argmax(y_pred)\n",
        "                if prediction == y[idx]:\n",
        "                    corr += 1.\n",
        "                total+=1\n",
        "    return corr/total, total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrFLqdC4ZQJL"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, bert_model_name, params):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model_name=bert_model_name\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name, do_lower_case=params[\"doLowerCase\"], do_basic_tokenize=False)\n",
        "        self.bert = BertModel.from_pretrained(self.model_name)\n",
        "\n",
        "        self.num_labels = params[\"label_length\"]\n",
        "\n",
        "        self.fc = nn.Linear(params[\"embedding_size\"], self.num_labels)\n",
        "\n",
        "    def get_batches(self, all_x, all_y, batch_size=16, max_toks=510):\n",
        "\n",
        "        \"\"\" Get batches for input x, y data, with data tokenized according to the BERT tokenizer\n",
        "      (and limited to a maximum number of WordPiece tokens \"\"\"\n",
        "\n",
        "        batches_x=[]\n",
        "        batches_y=[]\n",
        "\n",
        "        for i in range(0, len(all_x), batch_size):\n",
        "\n",
        "            current_batch=[]\n",
        "\n",
        "            x=all_x[i:i+batch_size]\n",
        "\n",
        "            batch_x = self.tokenizer(x, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_toks)\n",
        "            batch_y=all_y[i:i+batch_size]\n",
        "\n",
        "            batches_x.append(batch_x.to(device))\n",
        "            batches_y.append(torch.LongTensor(batch_y).to(device))\n",
        "\n",
        "        return batches_x, batches_y\n",
        "\n",
        "\n",
        "    def forward(self, batch_x):\n",
        "\n",
        "        bert_output = self.bert(input_ids=batch_x[\"input_ids\"],\n",
        "                         attention_mask=batch_x[\"attention_mask\"],\n",
        "                         token_type_ids=batch_x[\"token_type_ids\"],\n",
        "                         output_hidden_states=True)\n",
        "\n",
        "      # We're going to represent an entire document just by its [CLS] embedding (at position 0)\n",
        "      # And use the *last* layer output (layer -1)\n",
        "      # as a result of this choice, this embedding will be optimized for this purpose during the training process.\n",
        "\n",
        "        bert_hidden_states = bert_output['hidden_states']\n",
        "\n",
        "        out = bert_hidden_states[-1][:,0,:]\n",
        "\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out.squeeze()\n",
        "\n",
        "def confidence_intervals(accuracy, n, significance_level):\n",
        "    critical_value=(1-significance_level)/2\n",
        "    z_alpha=-1*norm.ppf(critical_value)\n",
        "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
        "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)\n",
        "\n",
        "\n",
        "def train_bert(bert_model_name, model_filename, train_x, train_y, dev_x, dev_y, labels, embedding_size=768, doLowerCase=None):\n",
        "\n",
        "    bert_model = BERTClassifier(bert_model_name, params={\"label_length\": len(labels), \"doLowerCase\":doLowerCase, \"embedding_size\":embedding_size})\n",
        "    bert_model.to(device)\n",
        "\n",
        "    batch_x, batch_y = bert_model.get_batches(train_x, train_y)\n",
        "    dev_batch_x, dev_batch_y = bert_model.get_batches(dev_x, dev_y)\n",
        "\n",
        "    optimizer = torch.optim.Adam(bert_model.parameters(), lr=1e-5)\n",
        "    cross_entropy=nn.CrossEntropyLoss()\n",
        "\n",
        "    num_epochs=30\n",
        "    best_dev_acc = 0.\n",
        "    patience=5\n",
        "\n",
        "    best_epoch=0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        bert_model.train()\n",
        "\n",
        "        # Train\n",
        "        for x, y in zip(batch_x, batch_y):\n",
        "            y_pred = bert_model.forward(x)\n",
        "            loss = cross_entropy(y_pred.view(-1, bert_model.num_labels), y.view(-1))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Evaluate\n",
        "        dev_accuracy, _=evaluate(bert_model, dev_batch_x, dev_batch_y)\n",
        "        if epoch % 1 == 0:\n",
        "            print(\"Epoch %s, dev accuracy: %.3f\" % (epoch, dev_accuracy))\n",
        "            if dev_accuracy > best_dev_acc:\n",
        "                torch.save(bert_model.state_dict(), model_filename)\n",
        "                best_dev_acc = dev_accuracy\n",
        "                best_epoch=epoch\n",
        "        if epoch - best_epoch > patience:\n",
        "            print(\"No improvement in dev accuracy over %s epochs; stopping training\" % patience)\n",
        "            break\n",
        "\n",
        "    bert_model.load_state_dict(torch.load(model_filename))\n",
        "    print(\"\\nBest Performing Model achieves dev accuracy of : %.3f\" % (best_dev_acc))\n",
        "    return bert_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGe-toFYZQHP"
      },
      "outputs": [],
      "source": [
        "bert_model_name=\"bert-base-cased\"\n",
        "model_filename=\"mybert.model\"\n",
        "embedding_size=768\n",
        "doLowerCase=False\n",
        "\n",
        "model=train_bert(bert_model_name, model_filename, train_x, train_y, dev_x, dev_y, labels, embedding_size=embedding_size, doLowerCase=doLowerCase)\n",
        "\n",
        "test_batch_x, test_batch_y = model.get_batches(test_x, test_y)\n",
        "accuracy, test_n=evaluate(model, test_batch_x, test_batch_y)\n",
        "\n",
        "lower, upper=confidence_intervals(accuracy, test_n, .95)\n",
        "print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Z9OvjHYjsx"
      },
      "source": [
        "# Problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyGM9SsyiMLF"
      },
      "source": [
        "## Problems we can see here:\n",
        "\n",
        "1. Classes are imbalance, should explore ways to balance out classes by the following methods\n",
        "\n",
        "*  Manually resample by repetition of existing minority class -> argument - I don't see the benefit for this because  Repetition can be using text augmentation and give more diversity with the same post but different words.\n",
        "\n",
        "*   Text augmentation - replace words wtih synonym replacement, random insertions, swaps, and deletion. Help with recognizing copy pasta post.\n",
        "\n",
        "\n",
        "2. preprocess text data because data models are recognizing stop words and url as label predictions in Logistics regression\n",
        "\n",
        "*   lowercase\n",
        "*   remove latin-1, ascii & hex characters\n",
        "*   extract mentions\n",
        "*   stop word removal\n",
        "*   remove URL\n",
        "*   turn emojis to word description\n",
        "*   remove self.berkeley and submitted by X year/hours ago\n",
        "*   replace emails, numbers, url\n",
        "*   Some unicode issues with quotations - definitely should use Reddit API instead of manually copy and paste reddit post in the future.\n",
        "\n",
        "\n",
        "3. Feature engineering techniques:\n",
        "\n",
        "*   repetitive word counts, (detecting copypasta) the higher means more likely to be troll post - achieve through text augmentation\n",
        "\n",
        "*   bad word list using opinion lexicon to detect sentiment, the higher means more likely to be troll post - using opinion lexicon\n",
        "*   emoji convert to text\n",
        "*   basic bag of word count\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbvNtok-JC-A",
        "outputId": "e8eaa5b9-bb0e-4947-c2e7-e37dbaad393d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog\n",
            "Augmented: ['The quick brown university george fox jumps concluded the lazy dog']\n"
          ]
        }
      ],
      "source": [
        "import nlpaug.augmenter.word as naw\n",
        "\n",
        "text_augmenter = naw.SynonymAug(aug_src='wordnet')\n",
        "\n",
        "# Example: Augmenting a single text string\n",
        "original_text = \"The quick brown fox jumps over the lazy dog\"\n",
        "augmented_text = text_augmenter.augment(original_text)\n",
        "print(\"Original:\", original_text)\n",
        "print(\"Augmented:\", augmented_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxIkGRoGAop1",
        "outputId": "7ce5309a-083b-400c-b788-8109474687be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Troll Rating\n",
            "1    141\n",
            "2     62\n",
            "3     42\n",
            "5     39\n",
            "4     16\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train['Troll Rating'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_swbFrpAooh",
        "outputId": "0e603675-d125-4b79-dfa2-3d98363834ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Troll Rating\n",
            "3    141\n",
            "5    141\n",
            "2    141\n",
            "1    141\n",
            "4    141\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Set all seeds for consistency\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "english_stopwords = stopwords.words('english')\n",
        "\n",
        "# Initialize the synonym augmenter\n",
        "text_augmenter = naw.SynonymAug(aug_src='wordnet', aug_p = random.uniform(0.3, 0.7), stopwords = english_stopwords)\n",
        "\n",
        "def augment_text(df, class_label, target_count, augmenter):\n",
        "    class_data = df[df['Troll Rating'] == class_label]\n",
        "    augmented_texts = []\n",
        "\n",
        "    needed = target_count - len(class_data)\n",
        "\n",
        "    while len(augmented_texts) < needed:\n",
        "        text_to_augment = class_data.sample(1, random_state=np.random.randint(low=1, high=10000))['Post'].values[0]\n",
        "        augmented_text = augmenter.augment(text_to_augment)\n",
        "\n",
        "        if isinstance(augmented_text, list):\n",
        "            augmented_text = ' '.join(augmented_text)\n",
        "\n",
        "        augmented_texts.append(augmented_text)\n",
        "\n",
        "    new_data = pd.DataFrame({\n",
        "        'index_id': random.sample(range(501, 1064), needed),\n",
        "        'adjudicated': 'adjudicated',\n",
        "        'Post': augmented_texts,\n",
        "        'Troll Rating': class_label\n",
        "    })\n",
        "\n",
        "    return pd.concat([df, new_data], ignore_index=True)\n",
        "\n",
        "# Apply augmentation\n",
        "train_augmented = train.copy()\n",
        "\n",
        "max_size = train['Troll Rating'].value_counts().max()\n",
        "\n",
        "\n",
        "for rating in [2, 3, 4, 5]:\n",
        "    train_augmented = augment_text(train_augmented, rating, max_size, text_augmenter)\n",
        "\n",
        "# Check the new value counts\n",
        "print(train_augmented['Troll Rating'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Eto_dD-gAojT",
        "outputId": "6c5f9ce0-29bd-4e08-fe26-f08bef73c810"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     index_id  adjudicated  Troll Rating  \\\n",
              "220         1  adjudicated             5   \n",
              "152         4  adjudicated             1   \n",
              "33          6  adjudicated             2   \n",
              "182         8  adjudicated             1   \n",
              "43         10  adjudicated             4   \n",
              "..        ...          ...           ...   \n",
              "423      1058  adjudicated             3   \n",
              "613      1059  adjudicated             5   \n",
              "675      1062  adjudicated             5   \n",
              "336      1062  adjudicated             2   \n",
              "567      1063  adjudicated             4   \n",
              "\n",
              "                                                  Post  \n",
              "220  Title: Dear Fellow UC Berkeley Students  I‚Äôve ...  \n",
              "152  Title: UniversityEnough is enough. It‚Äôs time t...  \n",
              "33   Seriously asking, do the protesters blocking t...  \n",
              "182   1 month ago by dewpydoodledooCS  On Sunday ni...  \n",
              "43   PSA to any non-Cal student lurking this subred...  \n",
              "..                                                 ...  \n",
              "423  What happened to all the Israel / Canaan mater...  \n",
              "613  Did not tell him he had a big ding a ling (ego...  \n",
              "675  Solution to homeless. Hello everybody 1 am an ...  \n",
              "336  About the recently circulating video, an apolo...  \n",
              "567  Incest (self. berkeley) submit 7 months ago by...  \n",
              "\n",
              "[705 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-317ce077-1c4b-4c7a-b4d7-7e113f800598\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index_id</th>\n",
              "      <th>adjudicated</th>\n",
              "      <th>Troll Rating</th>\n",
              "      <th>Post</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>1</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>5</td>\n",
              "      <td>Title: Dear Fellow UC Berkeley Students  I‚Äôve ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>4</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>1</td>\n",
              "      <td>Title: UniversityEnough is enough. It‚Äôs time t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>6</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>2</td>\n",
              "      <td>Seriously asking, do the protesters blocking t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>8</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>1</td>\n",
              "      <td>1 month ago by dewpydoodledooCS  On Sunday ni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>10</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>4</td>\n",
              "      <td>PSA to any non-Cal student lurking this subred...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>1058</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>3</td>\n",
              "      <td>What happened to all the Israel / Canaan mater...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>1059</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>5</td>\n",
              "      <td>Did not tell him he had a big ding a ling (ego...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>675</th>\n",
              "      <td>1062</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>5</td>\n",
              "      <td>Solution to homeless. Hello everybody 1 am an ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336</th>\n",
              "      <td>1062</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>2</td>\n",
              "      <td>About the recently circulating video, an apolo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>1063</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>4</td>\n",
              "      <td>Incest (self. berkeley) submit 7 months ago by...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>705 rows √ó 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-317ce077-1c4b-4c7a-b4d7-7e113f800598')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-317ce077-1c4b-4c7a-b4d7-7e113f800598 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-317ce077-1c4b-4c7a-b4d7-7e113f800598');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a9c830e-3789-490f-9061-97ad38435767\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a9c830e-3789-490f-9061-97ad38435767')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a9c830e-3789-490f-9061-97ad38435767 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_augmented\",\n  \"rows\": 705,\n  \"fields\": [\n    {\n      \"column\": \"index_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 305,\n        \"min\": 1,\n        \"max\": 1063,\n        \"num_unique_values\": 607,\n        \"samples\": [\n          988,\n          480,\n          143\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adjudicated\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"adjudicated\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Troll Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Post\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 704,\n        \"samples\": [\n          \"why the FUCK is Zoom logging me out of my other devices???? What the FUCKKK, I use TWO COMPUTERS, one is my PCCC and the other is a FUCKING LAPTOP  i use one for my FUCKING LAB CODE and the other to FUCKING SHOW MY LAB HARDWARE, and i join the FUCKING LABS WITH BOTH DEVICES THIS WHOLE SEMESTER  and now the DUMBASS CUNTS are not LETTING ME USE BOTH FOR WHATEVER RETARD REASON  who the FUCK MADE THIS DECISION????????????????????????????????????  I cant FUCKIN DO MY LAB, I need to keep LOGGING ON AND SWITCHING BETWEEN MY DEVICES  stop FUCKING AROUND YOU PRETENTIOUS DICKHEADS,  jesus christ, like this semester wasnt FUCKED already, these RETARD MORONS are doing DUMBASS SHIT LIKE THIS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 264
        }
      ],
      "source": [
        "train_augmented.sort_values('index_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "R6OQnbRfAogx",
        "outputId": "b3bf7efe-d1ea-4127-d8f8-379c1099ca0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/159 Proj Copy/splits/train_augmented.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 265
        }
      ],
      "source": [
        "# Save the splits to files\n",
        "train_augmented.to_csv(os.path.join(split_dir, 'train_augmented.txt'), sep='\\t', index=False, header=False)\n",
        "\n",
        "# Outputs the paths to the created files\n",
        "train_path = os.path.join(split_dir, 'train_augmented.txt')\n",
        "\n",
        "train_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16vsL6d7c02d"
      },
      "source": [
        "## Data Pre-Processing, Featurizing, Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEA9kj0tdJJY"
      },
      "outputs": [],
      "source": [
        "def load_data(filename):\n",
        "    X = []\n",
        "    Y = []\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            cols = line.split(\"\\t\")\n",
        "            idd = cols[0]\n",
        "            label = cols[2].lstrip().rstrip()\n",
        "            text = cols[3]\n",
        "\n",
        "            X.append(text)\n",
        "            Y.append(label)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "text, label = load_data(train_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LolvsFa_zTkG"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def clean_custom_text(text):\n",
        "    # Convert emojis to text\n",
        "    text = text.replace('self.berkeley', '')\n",
        "\n",
        "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "\n",
        "    # Use clean-text to perform standard cleaning\n",
        "    text = clean(text,\n",
        "                 fix_unicode=False,\n",
        "                 to_ascii=False,\n",
        "                 lower=True,                     # lowercase text -> may lose sentiment\n",
        "                 no_line_breaks=False,           # do not strip line breaks as opposed to only normalizing them\n",
        "                 no_urls=True,                   # replace all URLs with a special token\n",
        "                 no_emails=True,                 # replace all email addresses with a special token\n",
        "                 no_phone_numbers=True,          # replace all phone numbers with a special token\n",
        "                 no_numbers=False,               # do not replace all numbers with a special token\n",
        "                 no_digits=False,\n",
        "                 no_currency_symbols=False,\n",
        "                 no_punct=False,                 # do not remove punctuations to preserve sentiment\n",
        "                 replace_with_url=\"<URL>\",\n",
        "                 replace_with_email=\"<EMAIL>\",\n",
        "                 replace_with_phone_number=\"<PHONE>\",\n",
        "                 replace_with_number=\"<NUMBER>\",\n",
        "                 replace_with_currency_symbol=\"<CUR>\")\n",
        "\n",
        "    text = text.replace(\"\\\\'\", \"\")\n",
        "\n",
        "    # Regular expression to remove subreddit reference and metadata\n",
        "    text = re.sub(r'\\(.*?self\\.berkeley.*?\\)', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Regular expression to remove \"submitted X years/months/days/hours ago\"\n",
        "    text = re.sub(r'submitted\\s+\\d+\\s+(years?|months?|days?|hours?)\\s+ago', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Regular expression to remove \"by username\"\n",
        "    text = re.sub(r'\\s+by\\s+\\w+', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    doc = nlp(text)\n",
        "    lemmatized_text = ' '.join([token.lemma_ for token in doc if token.lemma_ not in stop_words and token.is_alpha])\n",
        "\n",
        "    # Further clean up to remove any stray tokens and ensure proper spacing\n",
        "    text = ' '.join(lemmatized_text.strip().split())\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "cleaned_posts = [clean_custom_text(post) for post in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuLtqmtAYqeF",
        "outputId": "5cb3a1a8-0a01-4800-ccd3-e947b76667fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why is race absent in WarnMe descriptions? title. doesn't make any logical sense - if you want to protect students its not helpful to know the color of their hoodie.  \n",
            " 3\n"
          ]
        }
      ],
      "source": [
        "def load_data(filename):\n",
        "    X = []\n",
        "    Y = []\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            cols = line.split(\"\\t\")\n",
        "            idd = cols[0]\n",
        "            label = cols[2].lstrip().rstrip()\n",
        "            text = cols[3]\n",
        "\n",
        "            X.append(text)\n",
        "            Y.append(label)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "trainingFile = \"splits/train_augmented.txt\"\n",
        "devFile = \"splits/dev.txt\"\n",
        "testFile = \"splits/test.txt\"\n",
        "\n",
        "trainX, trainY=load_data(trainingFile)\n",
        "devX, devY=load_data(devFile)\n",
        "testX, testY=load_data(testFile)\n",
        "\n",
        "print(trainX[0], trainY[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8Ni40mhkRC0"
      },
      "outputs": [],
      "source": [
        "cleaned_trainX = [clean_custom_text(post) for post in trainX]\n",
        "cleaned_devX = [clean_custom_text(post) for post in devX]\n",
        "cleaned_testX = [clean_custom_text(post) for post in testX]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uns4Xs7S2Ew7",
        "outputId": "5a6ec5f1-ee29-45e8-ed54-8c12e1eeaf3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "race absent warnme description title make logical sense want protect student helpful know color hoodie undecided voter see title I cal student undecided would like hear side I inform junior club nothing put resume I junior school I feel like transfer student I bother get involve campus since everyone talk toxic club culture I put resume since I anything really put I data science major take I could put final project course I would probably look like everyone else school since everyone project edit I mean diss transfer student I think similarly also would thing like club put resume since community college offer much term club people tend less involved since transfer admission much less base extracurricular activity\n"
          ]
        }
      ],
      "source": [
        "print(cleaned_trainX[0],cleaned_devX[0], cleaned_testX[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6BiIZe3VKyT",
        "outputId": "458e8a2b-56a3-4084-8089-6c5958fe1ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ],
      "source": [
        "# Load opinion lexicon\n",
        "positive_words = set(opinion_lexicon.positive())\n",
        "negative_words = set(opinion_lexicon.negative())\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJP-VpRLYb8c"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from textblob import TextBlob\n",
        "from nltk.corpus import opinion_lexicon\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "def bow_featurize(text):\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text.lower())\n",
        "\n",
        "    # Build basic BOW features\n",
        "    bow_features = {}\n",
        "    for token in tokens:\n",
        "        if token in bow_features:\n",
        "            bow_features[token] += 1\n",
        "        else:\n",
        "            bow_features[token] = 1\n",
        "\n",
        "    # Compute sentiment score using TextBlob\n",
        "    sentiment_score = TextBlob(text).sentiment.polarity\n",
        "    bow_features['sentiment_score'] = sentiment_score\n",
        "\n",
        "    # Compute opinion lexicon counts\n",
        "    pos_count = sum(1 for word in tokens if word in positive_words)\n",
        "    neg_count = sum(1 for word in tokens if word in negative_words)\n",
        "\n",
        "    bow_features['positive_count'] = pos_count\n",
        "    bow_features['negative_count'] = neg_count\n",
        "\n",
        "    return bow_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm_ov9vnnvwf"
      },
      "source": [
        "## Logistics Regression with Cleaning + New Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EthRpyMrdKWl",
        "outputId": "5d23605a-c2c8-46da-94d9-7d26e5d268e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.390, 95% CIs: [0.294 0.486]\n",
            "\n",
            "1\t0.328\tyear\n",
            "1\t0.249\tlast\n",
            "1\t0.219\twell\n",
            "1\t0.213\tfriend\n",
            "1\t0.208\thello\n",
            "1\t0.203\tthank\n",
            "1\t0.189\tscience\n",
            "1\t0.183\thaas\n",
            "1\t0.178\tphd\n",
            "1\t0.178\tcheck\n",
            "\n",
            "2\t0.234\tpost\n",
            "2\t0.200\tucla\n",
            "2\t0.178\tthink\n",
            "2\t0.168\tworld\n",
            "2\t0.159\tcome\n",
            "2\t0.144\tsocal\n",
            "2\t0.141\tclub\n",
            "2\t0.139\tmatter\n",
            "2\t0.136\tfinal\n",
            "2\t0.133\tu\n",
            "\n",
            "3\t0.287\tpeople\n",
            "3\t0.229\tget\n",
            "3\t0.221\tgsi\n",
            "3\t0.216\ttitle\n",
            "3\t0.203\tknow\n",
            "3\t0.201\tfood\n",
            "3\t0.181\tedit\n",
            "3\t0.181\tplease\n",
            "3\t0.168\tuse\n",
            "3\t0.161\tsmoke\n",
            "\n",
            "4\t0.151\tcheap\n",
            "4\t0.148\tcal\n",
            "4\t0.148\tright\n",
            "4\t0.136\tsurvive\n",
            "4\t0.129\tenough\n",
            "4\t0.123\ttear\n",
            "4\t0.115\teveryone\n",
            "4\t0.112\tdue\n",
            "4\t0.107\tpush\n",
            "4\t0.107\tsex\n",
            "\n",
            "5\t0.246\tsquirrel\n",
            "5\t0.224\tbear\n",
            "5\t0.203\ttry\n",
            "5\t0.195\tone\n",
            "5\t0.185\tsay\n",
            "5\t0.184\treal\n",
            "5\t0.182\tget\n",
            "5\t0.175\tsize\n",
            "5\t0.165\teec\n",
            "5\t0.164\tcs\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def run(trainingFile, devFile, testFile):\n",
        "    trainX, trainY=load_data(trainingFile)\n",
        "    devX, devY=load_data(devFile)\n",
        "    testX, testY=load_data(testFile)\n",
        "\n",
        "    cleaned_trainX = [clean_custom_text(post) for post in trainX]\n",
        "    cleaned_devX = [clean_custom_text(post) for post in devX]\n",
        "    cleaned_testX = [clean_custom_text(post) for post in testX]\n",
        "\n",
        "    simple_classifier = Classifier(bow_featurize, cleaned_trainX, trainY, cleaned_devX, devY, cleaned_testX, testY)\n",
        "    simple_classifier.train()\n",
        "    accuracy=simple_classifier.test()\n",
        "\n",
        "    lower, upper=confidence_intervals(accuracy, len(testY), .95)\n",
        "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))\n",
        "\n",
        "    simple_classifier.printWeights()\n",
        "\n",
        "\n",
        "\n",
        "trainingFile = \"splits/train.txt\"\n",
        "devFile = \"splits/dev.txt\"\n",
        "testFile = \"splits/test.txt\"\n",
        "\n",
        "run(trainingFile, devFile, testFile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrlUYBKwDcOR"
      },
      "source": [
        "## Logistics Regression with Cleaning + New Features + Text Augmentation w/ Fixed Class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGNmoypzDaR8",
        "outputId": "5e98b2ae-7c15-4dc5-ff95-5e26877addf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.380, 95% CIs: [0.285 0.475]\n",
            "\n",
            "1\t0.273\tlast\n",
            "1\t0.250\tyear\n",
            "1\t0.249\twell\n",
            "1\t0.240\thello\n",
            "1\t0.237\tthank\n",
            "1\t0.231\tfriend\n",
            "1\t0.230\tscience\n",
            "1\t0.216\tphd\n",
            "1\t0.205\tfact\n",
            "1\t0.202\tsub\n",
            "\n",
            "2\t0.328\tpost\n",
            "2\t0.264\tthink\n",
            "2\t0.246\tevaluation\n",
            "2\t0.235\tucla\n",
            "2\t0.217\tfinal\n",
            "2\t0.213\tmoney\n",
            "2\t0.213\tnorcal\n",
            "2\t0.207\tsocal\n",
            "2\t0.206\tclub\n",
            "2\t0.204\tlair\n",
            "\n",
            "3\t0.392\tgsi\n",
            "3\t0.373\tpeople\n",
            "3\t0.283\tgood\n",
            "3\t0.279\tedit\n",
            "3\t0.278\ttitle\n",
            "3\t0.269\ttwo\n",
            "3\t0.268\tget\n",
            "3\t0.261\tbring\n",
            "3\t0.243\tfood\n",
            "3\t0.231\tprotect\n",
            "\n",
            "4\t0.477\tquantitative\n",
            "4\t0.473\tfinance\n",
            "4\t0.421\ttard\n",
            "4\t0.371\tego\n",
            "4\t0.368\ttear\n",
            "4\t0.353\tfifth\n",
            "4\t0.295\tmoffit\n",
            "4\t0.288\tcheap\n",
            "4\t0.271\tago\n",
            "4\t0.253\tsurvive\n",
            "\n",
            "5\t0.337\thotbox\n",
            "5\t0.310\tsquirrel\n",
            "5\t0.307\tanal\n",
            "5\t0.282\tcalbearmatch\n",
            "5\t0.274\tcampus\n",
            "5\t0.256\ttry\n",
            "5\t0.254\tcholula\n",
            "5\t0.254\tsauce\n",
            "5\t0.253\tget\n",
            "5\t0.248\tpress\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def run(trainingFile, devFile, testFile):\n",
        "    trainX, trainY=load_data(trainingFile)\n",
        "    devX, devY=load_data(devFile)\n",
        "    testX, testY=load_data(testFile)\n",
        "\n",
        "    cleaned_trainX = [clean_custom_text(post) for post in trainX]\n",
        "    cleaned_devX = [clean_custom_text(post) for post in devX]\n",
        "    cleaned_testX = [clean_custom_text(post) for post in testX]\n",
        "\n",
        "    simple_classifier = Classifier(bow_featurize, cleaned_trainX, trainY, cleaned_devX, devY, cleaned_testX, testY)\n",
        "    simple_classifier.train()\n",
        "    accuracy=simple_classifier.test()\n",
        "\n",
        "    lower, upper=confidence_intervals(accuracy, len(testY), .95)\n",
        "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))\n",
        "\n",
        "    simple_classifier.printWeights()\n",
        "\n",
        "\n",
        "\n",
        "trainingFile = \"splits/train_augmented.txt\"\n",
        "devFile = \"splits/dev.txt\"\n",
        "testFile = \"splits/test.txt\"\n",
        "\n",
        "run(trainingFile, devFile, testFile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY2vvprq24Gb"
      },
      "source": [
        "## Ordinal Regression with Cleaning + New Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPK-DgzTk4rS"
      },
      "outputs": [],
      "source": [
        "def run(trainingFile, devFile, testFile, ordinal_values):\n",
        "\n",
        "\n",
        "    trainX, trainY, orig_trainY=load_ordinal_data(trainingFile, ordinal_values)\n",
        "    devX, devY, orig_devY=load_ordinal_data(devFile, ordinal_values)\n",
        "    testX, testY, orig_testY=load_ordinal_data(testFile, ordinal_values)\n",
        "\n",
        "    cleaned_trainX = [clean_custom_text(post) for post in trainX]\n",
        "    cleaned_devX = [clean_custom_text(post) for post in devX]\n",
        "    cleaned_testX = [clean_custom_text(post) for post in testX]\n",
        "\n",
        "\n",
        "    simple_classifier = OrdinalClassifier(ordinal_values, bow_featurize, cleaned_trainX, trainY, cleaned_devX, devY, cleaned_testX, testY, orig_trainY, orig_devY, orig_testY)\n",
        "    simple_classifier.train()\n",
        "    accuracy=simple_classifier.test()\n",
        "\n",
        "    lower, upper=confidence_intervals(accuracy, len(testY[0]), .95)\n",
        "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSf2rgnInJU4",
        "outputId": "7748e649-ae9e-4d57-e8fd-3d48dd37c8dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.380, 95% CIs: [0.285 0.475]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainingFile = \"splits/train.txt\"\n",
        "devFile = \"splits/dev.txt\"\n",
        "testFile = \"splits/test.txt\"\n",
        "\n",
        "ordinal_values=[\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
        "\n",
        "run(trainingFile, devFile, testFile, ordinal_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV6LFGhck2Mh"
      },
      "source": [
        "## Ordinal Regression with Cleaning + New Features + Text Augumentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkQMBmzukwWx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "def run(trainingFile, devFile, testFile, ordinal_values):\n",
        "\n",
        "\n",
        "    trainX, trainY, orig_trainY=load_ordinal_data(trainingFile, ordinal_values)\n",
        "    devX, devY, orig_devY=load_ordinal_data(devFile, ordinal_values)\n",
        "    testX, testY, orig_testY=load_ordinal_data(testFile, ordinal_values)\n",
        "\n",
        "    cleaned_trainX = [clean_custom_text(post) for post in trainX]\n",
        "    cleaned_devX = [clean_custom_text(post) for post in devX]\n",
        "    cleaned_testX = [clean_custom_text(post) for post in testX]\n",
        "\n",
        "\n",
        "    simple_classifier = OrdinalClassifier(ordinal_values, bow_featurize, cleaned_trainX, trainY, cleaned_devX, devY, cleaned_testX, testY, orig_trainY, orig_devY, orig_testY)\n",
        "    simple_classifier.train()\n",
        "    accuracy=simple_classifier.test()\n",
        "\n",
        "    lower, upper=confidence_intervals(accuracy, len(testY[0]), .95)\n",
        "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB6cnwjdk61X",
        "outputId": "37da04be-ef74-46e0-8665-d61d61b2f9d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.290, 95% CIs: [0.201 0.379]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainingFile = \"splits/train_augmented.txt\"\n",
        "devFile = \"splits/dev.txt\"\n",
        "testFile = \"splits/test.txt\"\n",
        "\n",
        "ordinal_values=[\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
        "\n",
        "run(trainingFile, devFile, testFile, ordinal_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbw2JKu544GD"
      },
      "source": [
        "## BERT with Cleaning + New Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRDltEHinJQX",
        "outputId": "646a19dc-188d-4588-f5e8-73784bf51f41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on {}\".format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1HKKStN3j6m"
      },
      "outputs": [],
      "source": [
        "directory='/content/drive/MyDrive/159 Proj Copy/splits'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jkQVHj2INkG"
      },
      "outputs": [],
      "source": [
        "labels=read_labels(\"%s/train.txt\" % directory)\n",
        "train_x, train_y=read_data(\"%s/train.txt\" % directory, labels, max_data_points=None)\n",
        "dev_x, dev_y=read_data(\"%s/dev.txt\" % directory, labels, max_data_points=None)\n",
        "test_x, test_y=read_data(\"%s/test.txt\" % directory, labels, max_data_points=None)\n",
        "\n",
        "cleaned_trainX = [clean_custom_text(post) for post in train_x]\n",
        "cleaned_devX = [clean_custom_text(post) for post in dev_x]\n",
        "cleaned_testX = [clean_custom_text(post) for post in testX]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNGTdIabITpt",
        "outputId": "e9fbae6f-1a0a-4a0a-ba67-8859f066bc62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, dev accuracy: 0.450\n",
            "Epoch 1, dev accuracy: 0.450\n",
            "Epoch 2, dev accuracy: 0.450\n",
            "Epoch 3, dev accuracy: 0.440\n",
            "Epoch 4, dev accuracy: 0.420\n",
            "Epoch 5, dev accuracy: 0.450\n",
            "Epoch 6, dev accuracy: 0.440\n",
            "No improvement in dev accuracy over 5 epochs; stopping training\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.450\n",
            "Test accuracy for best dev model: 0.410, 95% CIs: [0.314 0.506]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Set all seeds for consistency\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "bert_model_name=\"bert-base-cased\"\n",
        "model_filename=\"mybert.model\"\n",
        "embedding_size=768\n",
        "doLowerCase=False\n",
        "\n",
        "model=train_bert(bert_model_name, model_filename, cleaned_trainX, train_y, cleaned_devX, dev_y, labels, embedding_size=embedding_size, doLowerCase=doLowerCase)\n",
        "\n",
        "test_batch_x, test_batch_y = model.get_batches(cleaned_testX, test_y)\n",
        "accuracy, test_n=evaluate(model, test_batch_x, test_batch_y)\n",
        "\n",
        "lower, upper=confidence_intervals(accuracy, test_n, .95)\n",
        "print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR10VkIMKm5u"
      },
      "source": [
        "## BERT with Text Augumentation w/Fixed class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3avwd_dITk_"
      },
      "outputs": [],
      "source": [
        "labels=read_labels(\"%s/train_augmented.txt\" % directory)\n",
        "train_x, train_y=read_data(\"%s/train_augmented.txt\" % directory, labels, max_data_points=None)\n",
        "dev_x, dev_y=read_data(\"%s/dev.txt\" % directory, labels, max_data_points=None)\n",
        "test_x, test_y=read_data(\"%s/test.txt\" % directory, labels, max_data_points=None)\n",
        "\n",
        "# cleaned_trainX = [clean_custom_text(post) for post in train_x]\n",
        "# cleaned_devX = [clean_custom_text(post) for post in dev_x]\n",
        "# cleaned_testX = [clean_custom_text(post) for post in testX]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRCR8390K3TA",
        "outputId": "7746f0ff-7c5f-48e9-fb50-898012530857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, dev accuracy: 0.340\n",
            "Epoch 1, dev accuracy: 0.420\n",
            "Epoch 2, dev accuracy: 0.420\n",
            "Epoch 3, dev accuracy: 0.460\n",
            "Epoch 4, dev accuracy: 0.470\n",
            "Epoch 5, dev accuracy: 0.490\n",
            "Epoch 6, dev accuracy: 0.500\n",
            "Epoch 7, dev accuracy: 0.450\n",
            "Epoch 8, dev accuracy: 0.460\n",
            "Epoch 9, dev accuracy: 0.440\n",
            "Epoch 10, dev accuracy: 0.430\n",
            "Epoch 11, dev accuracy: 0.430\n",
            "Epoch 12, dev accuracy: 0.430\n",
            "No improvement in dev accuracy over 5 epochs; stopping training\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.500\n",
            "Test accuracy for best dev model: 0.440, 95% CIs: [0.343 0.537]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Set all seeds for consistency\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "bert_model_name=\"bert-base-cased\"\n",
        "model_filename=\"mybert.model\"\n",
        "embedding_size=768\n",
        "doLowerCase=False\n",
        "\n",
        "model=train_bert(bert_model_name, model_filename, train_x, train_y, dev_x, dev_y, labels, embedding_size=embedding_size, doLowerCase=doLowerCase)\n",
        "\n",
        "test_batch_x, test_batch_y = model.get_batches(test_x, test_y)\n",
        "accuracy, test_n=evaluate(model, test_batch_x, test_batch_y)\n",
        "\n",
        "lower, upper=confidence_intervals(accuracy, test_n, .95)\n",
        "print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPJKSH6MMngQ"
      },
      "source": [
        "## BERT with Cleaning + Text Augumentation w/Fixed class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfmJopcVMo9g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "54d7d2e9-e42d-43b4-a0c6-e0d978dc0578"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'read_labels' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9dcad13a7796>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s/train_augmented.txt\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s/train_augmented.txt\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_data_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdev_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s/dev.txt\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_data_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s/test.txt\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_data_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'read_labels' is not defined"
          ]
        }
      ],
      "source": [
        "labels=read_labels(\"%s/train_augmented.txt\" % directory)\n",
        "train_x, train_y=read_data(\"%s/train_augmented.txt\" % directory, labels, max_data_points=None)\n",
        "dev_x, dev_y=read_data(\"%s/dev.txt\" % directory, labels, max_data_points=None)\n",
        "test_x, test_y=read_data(\"%s/test.txt\" % directory, labels, max_data_points=None)\n",
        "\n",
        "cleaned_trainX = [clean_custom_text(post) for post in train_x]\n",
        "cleaned_devX = [clean_custom_text(post) for post in dev_x]\n",
        "cleaned_testX = [clean_custom_text(post) for post in testX]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl0QHfiCMo5X",
        "outputId": "ebca4cf5-4bde-4eb9-92c4-87e8be7415ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, dev accuracy: 0.140\n",
            "Epoch 1, dev accuracy: 0.350\n",
            "Epoch 2, dev accuracy: 0.350\n",
            "Epoch 3, dev accuracy: 0.420\n",
            "Epoch 4, dev accuracy: 0.420\n",
            "Epoch 5, dev accuracy: 0.440\n",
            "Epoch 6, dev accuracy: 0.410\n",
            "Epoch 7, dev accuracy: 0.440\n",
            "Epoch 8, dev accuracy: 0.420\n",
            "Epoch 9, dev accuracy: 0.440\n",
            "Epoch 10, dev accuracy: 0.440\n",
            "Epoch 11, dev accuracy: 0.440\n",
            "No improvement in dev accuracy over 5 epochs; stopping training\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.440\n",
            "Test accuracy for best dev model: 0.350, 95% CIs: [0.257 0.443]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Set all seeds for consistency\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "bert_model_name=\"bert-base-cased\"\n",
        "model_filename=\"mybert.model\"\n",
        "embedding_size=768\n",
        "doLowerCase=False\n",
        "\n",
        "model=train_bert(bert_model_name, model_filename, cleaned_trainX, train_y, cleaned_devX, dev_y, labels, embedding_size=embedding_size, doLowerCase=doLowerCase)\n",
        "\n",
        "test_batch_x, test_batch_y = model.get_batches(cleaned_testX, test_y)\n",
        "accuracy, test_n=evaluate(model, test_batch_x, test_batch_y)\n",
        "\n",
        "lower, upper=confidence_intervals(accuracy, test_n, .95)\n",
        "print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4t_7BKj6ISJ"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ordinal Logistic Regression Confusion Matrix\n"
      ],
      "metadata": {
        "id": "3lsfdl9sUvtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our confusion matrix we can see that our model performs the best at predicitng labels with 1 with 30 instances correctly predicted. This may be due to the abduance of 1 labels in our data which makes sense for the model to better at predicitng them. Something seen is that posts labeled are often represented as 1 instead. This problem may be more systematic with our model and deifnitons. Our models may just heavily perfer to label a post as 1 rather than 2 due to lack of 2 labels, the defintions between 1 and 2 may also be too closely linked making it harder to differeniate each other. Our model in general struggles to predict labels 4 in and 5. This may just be due to the pure subtely used in the trolling posts, which may be leading it to becoming more confused. Our model may represent some overfitting to the data which is represented by this confusion matrix. This is further seen with certain key words leading to big impacts in our models prediciton score."
      ],
      "metadata": {
        "id": "i2j3Hz7MU2g5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foXKu8UeUn4g"
      },
      "source": [
        "### Does your model learn features of the phenomenon that you didn't consider in your guidelines that might cause you to rethink the category boundaries?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXwxcvvMVDZx"
      },
      "source": [
        "No, I think the model has been coherent with our guidelines base on the result of weights in logistics regression. However, I believe models that uses attention mechanism perform much better than regression methods because of the context that the model understand. This is also the reason why augumentation help improve test accuracy in BERT modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBrwL1atU2F9"
      },
      "source": [
        "###  What features are learned to most define the classes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYwevBKtVFAs"
      },
      "source": [
        "Looking at initial logistics regression weights without any procesing, my model was learning stop words, url links and other metadata, quotations. Therefore, I thought applying text cleaning may help the model benefit from the words. After applying text cleaning, text augmentation, and featurizing. The test accuracy dropped, however, the weights of declaring the labels seem to match our guidelines.\n",
        "\n",
        "For labels that are \"1\" - it was \"phd\" \"thank\" \"friend\", etc which I think it often relates to serious post because serious post often show appreciateness and academic oriented - one of the goals the berkeley reddit forum is for.\n",
        "\n",
        "For labels that are \"2\" - \"ucla\", \"money\", \"socal\", \"norcal\" - these show a level of seriousness because it may relates to serious events like deciding between ucla and cal (go bears!), and geographic location differences and adaption. But these can turned into trolling such as jokes around ucla and the cultural differences of socal and norcal.\n",
        "\n",
        "For labels that are \"3\" - medium trolling - \"gsi\" this is often misleading as there were multiple stories of serious post of falling in love with their gsi and trolling posts of copy pasta of squirrels falling in love with their gsi.\n",
        "\n",
        "For labels that \"4\" - medium to trolling - I think this may not be enough data to label this class after oversampling. There was only 16 post so oversampling this will cause \"quantitivate\" \"finance\" to have heavy weights.\n",
        "\n",
        "For labels that are \"5\" - trolling post - \"squirrel\", \"anal\", \"hotbox\" was the top 3 weights. I think this maybe a good representation because squirrel is often used to replace with the person and turned into copy pasta or people come up with squirrel jokes. However, there was a trend of posting squirrel photos before that would label as serious post. Our guide also had sexualizing others and sexual contents. Additionally, the use of slang words often represent trolling post.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1XUzz0uU4i7"
      },
      "source": [
        "### Are there any biases your model makes? (E.g., by performing worse on different dialects or registers of the language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y9RXe4rVGCU"
      },
      "source": [
        "I think the bias I saw was due to low sample size for the labels. I only have 16 labels for \"4\" medium to trolling posts, after cleaning and augumentation the logistics model instead of recognizing the content, recognize words that appear often in label \"4\" to predict \"4\". This is exhibited in our ordinal logistic regression model with more emphasis on overfitting to common words woth 4 rating. A solution to this will be gather more rating \"4\" labels with diversify posts on Reddit. A possible solution would be a script that scowers a wider range of reddit posts in order to possibly incorporate more 4 ratings to counter this overfitting issue.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X2AqDZGU4W8"
      },
      "source": [
        "### Think about the level of balance in your dataset: Is one label extremely prevalent? How could this impact the model you developed? Is your dataset a good candidate for strategies like oversampling or changing class weights?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcvkWw2fVGha"
      },
      "source": [
        "Yes, Label \"1\" as serious post is prevalent being the majority class of 161 counts compared to other classes.\n",
        "\n",
        "Troll Rating counts\n",
        "1. 141\n",
        "2. 62\n",
        "3. 42\n",
        "4. 16\n",
        "5. 39\n",
        "\n",
        "This can impact the model from not being able to generalize the sentiment and the difference with other classes. I think my dataset is better suited with text arugmentation as oversampling technique to match the majority counts. Thereby making it\n",
        "\n",
        "Troll Rating counts\n",
        "1. 141\n",
        "2. 141\n",
        "3. 141\n",
        "4. 141\n",
        "5. 141\n",
        "\n",
        "Increase change class weights will lead to another question, how much weights we should assign for each class and how much is fair? - Because we cannot answer this question so my team approach this by text argumentation - randomly changing, considering 30% - 70% of the post and randomly changing words with synonyms to generate new posts.\n",
        "\n",
        "I did a comparison of each model with 3 techniques: cleaning + featurizing (adding sentiment score, bag of words count, postive + negative word count) + augmentation and cleaning + featurizing, dataset without any changes\n",
        "\n",
        "Cleaning the text was not beneficial as it loses the tone and words that a person write can be random, misleading so applying text cleaning methods may replace these randomness so this maybe the reason why it loses accuracy for all models.\n",
        "\n",
        "Text augmentation decreased performance BERT modeling, worst performance in ordinary regression, and decrease in performance for logistics regression. The reason is because our troll post detecting goal, it is not beneficial to featurize as bag of words, rather we need attention mechanism from BERT and masking to understand the whole sentence's rather than ranks and single words like the regression mehtods. Troll post often need to consider sentence context."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What kind of systematic mistakes does your model make? This could involve reading through test predictions and manually categorizing mistakes that are made"
      ],
      "metadata": {
        "id": "dLXPJmTQP1ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One systematic mistake our model makes is that can Trolling can manifest in various forms that might not always include obvious keywords or repeated patterns. The reliance on bag-of-words models and even the initial BERT models without adequate contextual training may miss subtler forms of trolling expressed through sarcasm, irony, or cultural references. This is seen especially with our ordinal logstic regression model in which our model tends over predict posts as 1 rather than 2, this may be due to the definitons of these buckets being two closley linked to one another. ANother representation of systemic mistakes from the logistic regression model comes from the lack of prediciton on the 4 to 5 once again hinting at the model overfitting to certain key words and not looking for other indicators of trolling, and sarcasm in the posts."
      ],
      "metadata": {
        "id": "q6-i_ExkQw5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5H_ADJw9P8h7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n22cKlehP7N_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "jw8XtDi-H-nL",
        "OQWXEf9RoPhc",
        "mnLJu4lHoR9W"
      ],
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}